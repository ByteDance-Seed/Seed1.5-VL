{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05f96644-74d3-4d63-830c-8470fd2224d6",
   "metadata": {},
   "source": [
    "## Cookbook for Video Understanding with Seed1.5-VL\n",
    "\n",
    "Seed1.5-VL provides strong video understanding abilities. Here are a few simple examples to quickly show you how to leverage the Seed1.5-VL for video understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49439a0b-1cfb-4d8b-b0f2-b55c6474a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2025 Bytedance Ltd. and/or its affiliates\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "from typing import Optional\n",
    "from enum import Enum\n",
    "import os\n",
    "import base64\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78392a4-8786-464a-b155-934fed25dfa1",
   "metadata": {},
   "source": [
    "### 0. Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e54d43-9f95-418a-a7ed-e1b418965516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please set the API key here\n",
    "seed_vl_version = \"doubao-1-5-thinking-vision-pro-250428\"\n",
    "client = OpenAI(\n",
    "    base_url=\"https://ark.cn-beijing.volces.com/api/v3\",\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed96287d-8fd1-454b-9bfd-9f0eaff6c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义抽帧策略枚举类\n",
    "class Strategy(Enum):\n",
    "    # 固定间隔抽帧策略，例如每1秒抽一帧\n",
    "    CONSTANT_INTERVAL = \"constant_interval\"\n",
    "    # 均匀间隔抽帧策略，根据设定的最大帧数均匀从视频全长度抽取\n",
    "    EVEN_INTERVAL = \"even_interval\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33aad48-c939-4bf3-beef-9b5efc7d442b",
   "metadata": {},
   "source": [
    "Video processing code from [the doc of Volcengine](https://www.volcengine.com/docs/82379/1362931#%E7%A4%BA%E4%BE%8B%E4%BB%A3%E7%A0%81-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "974013e8-6436-403f-a5a3-fa245f322939",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_video(\n",
    "        video_file_path: str,\n",
    "        output_dir: str,\n",
    "        extraction_strategy: Optional[Strategy] = Strategy.EVEN_INTERVAL,\n",
    "        interval_in_seconds: Optional[float] = 1,\n",
    "        max_frames: Optional[int] = 10,\n",
    "        use_timestamp: bool = True,\n",
    "        keyframe_naming_template: str = \"frame_{:04d}.jpg\",\n",
    ") -> list[str]:\n",
    "    \"\"\"将视频按照指定策略抽帧\n",
    "    参数:\n",
    "        video_file_path (str): 视频文件路径\n",
    "        output_dir (str): 输出目录\n",
    "        extraction_strategy (Optional[Strategy], optional): 抽帧策略。\n",
    "             固定间隔 比如 1s 抽一帧 或\n",
    "             均匀间隔 根据设定的最大帧数 均匀从视频全长度均匀抽取\n",
    "             默认固定间隔 1s 抽一帧\n",
    "        interval_in_seconds (Optional[float], optional): 固定间隔抽帧的间隔时间. 默认 1s 抽一帧\n",
    "        max_frames (Optional[int], optional): 最大抽帧帧数. 默认 10 帧\n",
    "        use_timestamp (bool): 是否输出视频时间戳, 默认True\n",
    "        keyframe_naming_template (_type_, optional): 抽帧图片命名模板\n",
    "    返回:\n",
    "        list[str]: 抽帧图片路径列表\n",
    "        list[float]: 视频采样帧对应的时间戳\n",
    "    \"\"\"\n",
    "    # 检查输出目录是否存在，如果不存在则创建\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    # 使用OpenCV打开视频文件\n",
    "    cap = cv2.VideoCapture(video_file_path)\n",
    "    # 获取视频的帧率\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    # 获取视频的总帧数\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # 根据策略选择抽帧间隔\n",
    "    if extraction_strategy == Strategy.CONSTANT_INTERVAL:\n",
    "        # 计算固定间隔抽帧的帧间隔\n",
    "        frame_interval = int(fps * interval_in_seconds)\n",
    "    elif extraction_strategy == Strategy.EVEN_INTERVAL:\n",
    "        # 计算均匀间隔抽帧的帧间隔\n",
    "        frame_interval = int(length / max_frames)\n",
    "    else:\n",
    "        # 如果策略无效，抛出异常\n",
    "        raise ValueError(\"Invalid extraction strategy\")\n",
    "    # 初始化帧计数器\n",
    "    frame_count = 0\n",
    "    # 初始化关键帧列表\n",
    "    keyframes = []\n",
    "    timestamps = []\n",
    "    # 循环读取视频帧\n",
    "    while True:\n",
    "        # 读取一帧\n",
    "        ret, frame = cap.read()\n",
    "        # 如果读取失败，跳出循环\n",
    "        if not ret:\n",
    "            break\n",
    "        # 如果当前帧是关键帧\n",
    "        if frame_count % frame_interval == 0:\n",
    "            # 生成关键帧的文件名\n",
    "            image_path = os.path.join(\n",
    "                output_dir, keyframe_naming_template.format(len(keyframes))\n",
    "            )\n",
    "            # 将关键帧保存为图片\n",
    "            cv2.imwrite(\n",
    "                image_path,\n",
    "                frame,\n",
    "            )\n",
    "            # 将关键帧路径添加到列表中\n",
    "            keyframes.append(image_path)\n",
    "            timestamps.append(round(frame_count / fps, 1))\n",
    "        # 增加帧计数器\n",
    "        frame_count += 1\n",
    "        # 如果关键帧数量达到最大值，跳出循环\n",
    "        if len(keyframes) >= max_frames:\n",
    "            break\n",
    "\n",
    "    print(\"抽取帧数:\", len(keyframes))\n",
    "    # 返回关键帧路径列表\n",
    "    if use_timestamp:\n",
    "        return keyframes, timestamps\n",
    "    return keyframes, None\n",
    "\n",
    "def resize(image):\n",
    "    \"\"\"\n",
    "    调整图片大小以适应指定的尺寸。\n",
    "    参数:\n",
    "        image (numpy.ndarray): 输入的图片，格式为numpy数组。\n",
    "    返回:\n",
    "        numpy.ndarray: 调整大小后的图片。\n",
    "    \"\"\"\n",
    "    # 获取图片的原始高度和宽度\n",
    "    height, width = image.shape[:2]\n",
    "    # 根据图片的宽高比确定目标尺寸\n",
    "    if height < width:\n",
    "        target_height, target_width = 480, 640\n",
    "    else:\n",
    "        target_height, target_width = 640, 480\n",
    "    # 如果图片尺寸已经小于或等于目标尺寸，则直接返回原图片\n",
    "    if height <= target_height and width <= target_width:\n",
    "        return image\n",
    "    # 计算新的高度和宽度，保持图片的宽高比\n",
    "    if height / target_height < width / target_width:\n",
    "        new_width = target_width\n",
    "        new_height = int(height * (new_width / width))\n",
    "    else:\n",
    "        new_height = target_height\n",
    "        new_width = int(width * (new_height / height))\n",
    "    # 调整图片大小\n",
    "    return cv2.resize(image, (new_width, new_height))\n",
    "\n",
    "# 定义方法将指定路径图片resize到合适大小并转为Base64编码\n",
    "def encode_image(image_path: str) -> str:\n",
    "    \"\"\"\n",
    "    将指定路径的图片进行编码\n",
    "    参数:\n",
    "        image_path (str): 图片文件的路径\n",
    "    返回:\n",
    "        str: 编码后的图片字符串\n",
    "    \"\"\"\n",
    "    # 读取图片\n",
    "    image = cv2.imread(image_path)\n",
    "    # 调整图片大小\n",
    "    image_resized = resize(image)\n",
    "    # 将图片编码为JPEG格式\n",
    "    _, encoded_image = cv2.imencode(\".jpg\", image_resized)\n",
    "    # 将编码后的图片转换为Base64字符串\n",
    "    return base64.b64encode(encoded_image).decode(\"utf-8\")\n",
    "\n",
    "def construct_messages(image_paths: list[str], timestamps: list[float], prompt: str) -> list[dict]:\n",
    "    \"\"\"\n",
    "    构造包含文本和图像的消息列表。\n",
    "    参数:\n",
    "        image_paths (list[str]): 图像文件路径列表。\n",
    "        timestamps (list[float]): 视频的时间戳。\n",
    "        prompt (str): 文本提示。\n",
    "    返回:\n",
    "        list[dict]: 包含文本和图像的消息列表。\n",
    "    \"\"\"\n",
    "    # 初始化消息内容列表\n",
    "    content = []\n",
    "    # 遍历图像路径列表\n",
    "    for idx, image_path in enumerate(image_paths):\n",
    "        # 为每个图像路径构造一个图像URL消息\n",
    "        if timestamps is not None:\n",
    "            content.append({\n",
    "                \"type\": \"text\",\n",
    "                \"text\": f'[{timestamps[idx]} second]'\n",
    "            })\n",
    "        content.append(\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    # 使用Base64编码将图像转换为数据URL\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encode_image(image_path)}\",\n",
    "                    # 指定图像细节级别为低\n",
    "                    \"detail\":\"low\"\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    content.append(\n",
    "        {\n",
    "            \"type\": \"text\",\n",
    "            \"text\": prompt,\n",
    "    })\n",
    "    # 返回包含文本和图像的消息列表\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": content,\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def api_complete(client, messages):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=seed_vl_version,\n",
    "        messages=messages)\n",
    "    return response.choices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f05c7f0-6b26-4b51-99c2-5658a277881d",
   "metadata": {},
   "source": [
    "### 1. General Video Question-Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f48fd468-12d6-46c9-ae19-c2c981bdc6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取帧数: 24\n",
      "Seed1.5-VL: The video showcases a female athlete competing in the **high jump** at an outdoor track - and - field event. Here is a detailed breakdown:  \n",
      "\n",
      "\n",
      "### Scene Setting  \n",
      "The event takes place on a blue - colored running track. In the background, there are brick buildings, grassy areas, spectators, and officials. Some spectators are standing behind barriers, while others are sitting or walking around. There are also sports equipment and supplies, such as Gatorade coolers and umbrellas for shade.  \n",
      "\n",
      "\n",
      "### Athlete’s First Attempt  \n",
      "1. **Preparation**: The athlete, dressed in a yellow and white track suit and bright green running shoes, gets ready on the track. She seems to be mentally preparing herself and visualizing the jump.  \n",
      "2. **Run - up**: She starts her run - up, gradually picking up speed. Her strides become longer, and her arms swing in coordination with her body to build momentum.  \n",
      "3. **Takeoff**: With one foot pushing off the ground powerfully, she leaps into the air. Her body is fully extended as she aims for the bar.  \n",
      "4. **Clearing the Bar (Fosbury Flop)**: Using the *Fosbury Flop* technique, she arches her back and smoothly glides over the horizontal bar.  \n",
      "5. **Landing**: She lands on her back on the large red and blue high - jump mat (marked with “UCS” and a logo). After landing, she gets up and steps off the mat.  \n",
      "\n",
      "\n",
      "### Athlete’s Second Attempt (Repeated Sequence)  \n",
      "The video then shows the athlete going through the entire high - jump process once more:  \n",
      "- She prepares on the track, starts her run - up, takes off, clears the bar with the Fosbury Flop technique, and lands on the mat. After landing, she stands up and leaves the mat.  \n",
      "\n",
      "\n",
      "### Background Activity  \n",
      "Throughout the video, officials and other participants can be seen in the background. Some officials are sitting and keeping records, while others are holding flags (possibly to signal the validity of the jump). Spectators and other athletes are either watching the event, resting, or preparing for their own competitions.  \n",
      "\n",
      "\n",
      "### Key Elements  \n",
      "- **Technique**: The athlete uses the Fosbury Flop, a common high - jump method where the athlete runs curved, takes off with one foot, and lands on the back.  \n",
      "- **Atmosphere**: The scene is that of a formal track - and - field competition, with organized seating, equipment, and staff, creating a professional sports environment.  \n",
      "\n",
      "\n",
      "In summary, the video focuses on the athlete’s skillful execution of the high jump, from preparation to landing, and captures the lively atmosphere of the track - and - field event.\n"
     ]
    }
   ],
   "source": [
    "video_path = \"samples/OcZeMOnLpTQ.mp4\"\n",
    "text_prompts = \"Describe this video in details.\"\n",
    "if os.path.exists(\"video_frames\"):\n",
    "    shutil.rmtree(\"video_frames\")\n",
    "# sampling video frames\n",
    "sampling_fps = 1\n",
    "max_frames = 30\n",
    "selected_images, timestamps = preprocess_video(\n",
    "    video_file_path=video_path,\n",
    "    output_dir=\"video_frames\",\n",
    "    extraction_strategy=Strategy.CONSTANT_INTERVAL,\n",
    "    interval_in_seconds=sampling_fps,\n",
    "    use_timestamp=True,\n",
    "    max_frames=max_frames\n",
    ")\n",
    "message = construct_messages(image_paths=selected_images, timestamps=timestamps, prompt=text_prompts)\n",
    "result = api_complete(client, message)\n",
    "print(\"Seed1.5-VL:\", result.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3ce570-7ac2-4c58-9de2-aea4c4e2954a",
   "metadata": {},
   "source": [
    "### 2. Video Temporal Grounding\n",
    "The Seed1.5-VL has powerful video temporal localization capabilities. Based on user prompts, it can locate the corresponding segments within the video and output them in the format of start and end seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89845b90-e976-45c1-84cd-7239963101ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取帧数: 24\n",
      "Seed1.5-VL: 第一次跳高：3 - 10秒；第二次跳高：12 - 21秒\n"
     ]
    }
   ],
   "source": [
    "video_path = \"samples/OcZeMOnLpTQ.mp4\"\n",
    "text_prompts = \"请输出视频中女人每一次跳高的精确起止时间，如果有多次，请分别输出每一次的起止时间\"\n",
    "if os.path.exists(\"video_frames\"):\n",
    "    shutil.rmtree(\"video_frames\")\n",
    "# sampling video frames\n",
    "sampling_fps = 1\n",
    "max_frames = 30\n",
    "selected_images, timestamps = preprocess_video(\n",
    "    video_file_path=video_path,\n",
    "    output_dir=\"video_frames\",\n",
    "    extraction_strategy=Strategy.CONSTANT_INTERVAL,\n",
    "    interval_in_seconds=sampling_fps,\n",
    "    use_timestamp=True,\n",
    "    max_frames=max_frames\n",
    ")\n",
    "message = construct_messages(image_paths=selected_images, timestamps=timestamps, prompt=text_prompts)\n",
    "result = api_complete(client, message)\n",
    "print(\"Seed1.5-VL:\", result.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7521df-55b1-4d97-b846-6aa79e9762b3",
   "metadata": {},
   "source": [
    "### 3. Dense Video Captioning\n",
    "Building upon its temporal grounding capabilities, the model exhibits time perception ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c4fbac9-5c82-447b-b174-bec330bd70df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抽取帧数: 24\n",
      "Seed1.5-VL: 1. 第一次助跑加速：0 - 5秒，女子在跑道上准备后开始助跑，快速冲向跳高架。  \n",
      "2. 第一次起跳过杆：5 - 10秒，女子起跳腾空，身体越过横杆后落在垫上。  \n",
      "3. 第一次落地后起身：10 - 13秒，女子在跳高垫上起身并走下垫子。  \n",
      "4. 第二次助跑加速：13 - 18秒，女子回到跑道再次助跑，向跳高架加速冲刺。  \n",
      "5. 第二次起跳过杆：18 - 22秒，女子起跳腾空越过横杆，落地后在垫上起身。\n"
     ]
    }
   ],
   "source": [
    "video_path = \"samples/OcZeMOnLpTQ.mp4\"\n",
    "text_prompts = \"Please watch this video carefully and find out all key events in this video, and output the events along with the start/end timestamps.\"\n",
    "if os.path.exists(\"video_frames\"):\n",
    "    shutil.rmtree(\"video_frames\")\n",
    "# sampling video frames\n",
    "sampling_fps = 1\n",
    "max_frames = 30\n",
    "selected_images, timestamps = preprocess_video(\n",
    "    video_file_path=video_path,\n",
    "    output_dir=\"video_frames\",\n",
    "    extraction_strategy=Strategy.CONSTANT_INTERVAL,\n",
    "    interval_in_seconds=sampling_fps,\n",
    "    use_timestamp=True,\n",
    "    max_frames=max_frames\n",
    ")\n",
    "message = construct_messages(image_paths=selected_images, timestamps=timestamps, prompt=text_prompts)\n",
    "result = api_complete(client, message)\n",
    "print(\"Seed1.5-VL:\", result.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d99a74-6eaf-4b7f-aac4-c3fb2059736f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
